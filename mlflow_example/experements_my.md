# Отчет по моим эксперементам в MLflow

* http://158.160.2.37:5000/#/experiments/21?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D

В равных условиях, на одинаком наборе фичей, 
для заданного набора значений гиперпараметра сравниваются метрики качества 
**(accuracy, f1, precision, recall, roc-auc, pr-auc)** 
по ним определяется лучшее значение исследуемого гиперпараметра

![all my experements](experements_graphics/my_all.jpg)

По значениям метрик качества в проведённых экспериментах наиболее эффективными можно назвать модели
градиентного бустинга над решающими деревьями со значениями learning rate 0.1, 0.2 и 0.3, 
а также все модели случайного леса над решающими деревьями и решающее дерево с глубиной 10. 

Как часто бывает наиболее эффективными при работе с табличными данными оказались решающие деревья и ансамбли из них)

### Сравнение lr (learning rate) для градиентного бустинга

Сравнивались значения: full-size, 0.01, 0.1, 0.2, 0.3

![my lr for grad boosting experements](experements_graphics/my_grad_boosting_lr.png)

Для всех рассмотренных значений **lr** большинство метрик качества имеют очень близкие значения,
но при значении 0.01 модель сильно отстаёт от остальных по метрикам f1, pr_auc, roc_auc и recall, 
хотя precision - очень высокий 0.99. При значении **0.3** модель имеет стабилно высокий результат по всем метрикам, 
значит в рамках этих результатов эксперимента полагаем данное значение лучшим для рассматриваемого гиперпараметра.

### Сравнение estimators (кол-во дереьев) для случайного леса

Сравнивались значения 50, 100, 150, 200

![my estimators for random forest experements](experements_graphics/my_random_forest_estimators.png)

Для всех рассмотренных значений **estimators** все метрики качества имеют очень близкие значения,
но этот гиперпараметр имеет прямое влияние на архитектуру модели - вес и вычислительную сложность. 
Тогда если наиболее лёгкая модель имеет метрики качества на том же уровне, что и более тяжёлые модели,
то в рамках этих результатов эксперимента полагаем наименьшее значение (**50**) лучшим для рассматриваемого гиперпараметра.

### Сравнение depth для решающего дерева

Сравнивались значения 3, 5, 7, 10

![my depth for decision tree experements](experements_graphics/my_decision_tree_depth.png)

На всех метриках качества, кроме precision, наиболее высокое значение демонстрируем модель глубиной **10**,
значит в рамках этих результатов эксперимента полагаем данное значение лучшим для рассматриваемого гиперпараметра.
